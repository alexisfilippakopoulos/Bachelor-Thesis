{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and Transform Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "test_data = datasets.FashionMNIST(root='/data', train=False, transform=transform, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather the indices of each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_indices = {0: [], 1: [], 2: [], 3: [], 4: [], 5: [], 6: [], 7: [], 8: [], 9: []}\n",
    "\n",
    "for idx, target in enumerate(test_data.targets):\n",
    "    class_indices[int(target)].append(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create each client's test subsets according to: \n",
    "#### œÅ = (# of OOD samples / # of ID samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 6000, 7000, 8000, 9000, 10000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For client 1 with ID the classes [0, 1, 2, 3, 4] and OOD the classes [5, 6, 7, 8, 9]\n",
    "c1_r0_indices = class_indices[0] + class_indices[1] + class_indices[2] + class_indices[3] + class_indices[4]\n",
    "c1_r0_2_indices = c1_r0_indices + class_indices[5][:200] + class_indices[6][:200] + class_indices[7][:200] + class_indices[8][:200] + class_indices[9][:200]\n",
    "c1_r0_4_indices = c1_r0_indices + class_indices[5][:400] + class_indices[6][:400] + class_indices[7][:400] + class_indices[8][:400] + class_indices[9][:400]\n",
    "c1_r0_6_indices = c1_r0_indices + class_indices[5][:600] + class_indices[6][:600] + class_indices[7][:600] + class_indices[8][:600] + class_indices[9][:600]\n",
    "c1_r0_8_indices = c1_r0_indices + class_indices[5][:800] + class_indices[6][:800] + class_indices[7][:800] + class_indices[8][:800] + class_indices[9][:800]\n",
    "c1_r1_indices = c1_r0_indices + class_indices[5] + class_indices[6] + class_indices[7] + class_indices[8] + class_indices[9]\n",
    "\n",
    "len(c1_r0_indices), len(c1_r0_2_indices), len(c1_r0_4_indices), len(c1_r0_6_indices), len(c1_r0_8_indices), len(c1_r1_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 6000, 7000, 8000, 9000, 10000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For client 2 with ID the classes [5, 6, 7, 8, 9] and OOD the classes [0, 1, 2, 3, 4]\n",
    "c2_r0_indices = class_indices[5] + class_indices[6] + class_indices[7] + class_indices[8] + class_indices[9]\n",
    "c2_r0_2_indices = c2_r0_indices + class_indices[0][:200] + class_indices[1][:200] + class_indices[2][:200] + class_indices[3][:200] + class_indices[4][:200]\n",
    "c2_r0_4_indices = c2_r0_indices + class_indices[0][:400] + class_indices[1][:400] + class_indices[2][:400] + class_indices[3][:400] + class_indices[4][:400]\n",
    "c2_r0_6_indices = c2_r0_indices + class_indices[0][:600] + class_indices[1][:600] + class_indices[2][:600] + class_indices[3][:600] + class_indices[4][:600]\n",
    "c2_r0_8_indices = c2_r0_indices + class_indices[0][:800] + class_indices[1][:800] + class_indices[2][:800] + class_indices[3][:800] + class_indices[4][:800]\n",
    "c2_r1_indices = c2_r0_indices + class_indices[0] + class_indices[1] + class_indices[2] + class_indices[3] + class_indices[4]\n",
    "\n",
    "len(c2_r0_indices), len(c2_r0_2_indices), len(c2_r0_4_indices), len(c2_r0_6_indices), len(c2_r0_8_indices), len(c2_r1_indices) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 6000, 7000, 8000, 9000, 10000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1_r0_subset = Subset(dataset=test_data, indices=c1_r0_indices)\n",
    "c1_r0_2_subset = Subset(dataset=test_data, indices=c1_r0_2_indices)\n",
    "c1_r0_4_subset = Subset(dataset=test_data, indices=c1_r0_4_indices)\n",
    "c1_r0_6_subset = Subset(dataset=test_data, indices=c1_r0_6_indices)\n",
    "c1_r0_8_subset = Subset(dataset=test_data, indices=c1_r0_8_indices)\n",
    "c1_r1_subset = Subset(dataset=test_data, indices=c1_r1_indices)\n",
    "\n",
    "len(c1_r0_subset), len(c1_r0_2_subset), len(c1_r0_4_subset), len(c1_r0_6_subset), len(c1_r0_8_subset), len(c1_r1_subset) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 6000, 7000, 8000, 9000, 10000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2_r0_subset = Subset(dataset=test_data, indices=c2_r0_indices)\n",
    "c2_r0_2_subset = Subset(dataset=test_data, indices=c2_r0_2_indices)\n",
    "c2_r0_4_subset = Subset(dataset=test_data, indices=c2_r0_4_indices)\n",
    "c2_r0_6_subset = Subset(dataset=test_data, indices=c2_r0_6_indices)\n",
    "c2_r0_8_subset = Subset(dataset=test_data, indices=c2_r0_8_indices)\n",
    "c2_r1_subset = Subset(dataset=test_data, indices=c2_r1_indices)\n",
    "\n",
    "len(c2_r0_subset), len(c2_r0_2_subset), len(c2_r0_4_subset), len(c2_r0_6_subset), len(c2_r0_8_subset), len(c2_r1_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a DataLoader for each subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(157, 188, 219, 250, 282, 313)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1_r0_dl = DataLoader(dataset=c1_r0_subset, batch_size=32, shuffle=False, num_workers=0, pin_memory=True)\n",
    "c1_r0_2_dl = DataLoader(dataset=c1_r0_2_subset, batch_size=32, shuffle=False, num_workers=0, pin_memory=True)\n",
    "c1_r0_4_dl = DataLoader(dataset=c1_r0_4_subset, batch_size=32, shuffle=False, num_workers=0, pin_memory=True)\n",
    "c1_r0_6_dl = DataLoader(dataset=c1_r0_6_subset, batch_size=32, shuffle=False, num_workers=0, pin_memory=True)\n",
    "c1_r0_8_dl = DataLoader(dataset=c1_r0_8_subset, batch_size=32, shuffle=False, num_workers=0, pin_memory=True)\n",
    "c1_r1_dl = DataLoader(dataset=c1_r1_subset, batch_size=32, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "len(c1_r0_dl), len(c1_r0_2_dl), len(c1_r0_4_dl), len(c1_r0_6_dl), len(c1_r0_8_dl), len(c1_r1_dl) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(157, 188, 219, 250, 282, 313)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2_r0_dl = DataLoader(dataset=c2_r0_subset, batch_size=32, shuffle=False, num_workers=0, pin_memory=True)\n",
    "c2_r0_2_dl = DataLoader(dataset=c2_r0_2_subset, batch_size=32, shuffle=False, num_workers=0, pin_memory=True)\n",
    "c2_r0_4_dl = DataLoader(dataset=c2_r0_4_subset, batch_size=32, shuffle=False, num_workers=0, pin_memory=True)\n",
    "c2_r0_6_dl = DataLoader(dataset=c2_r0_6_subset, batch_size=32, shuffle=False, num_workers=0, pin_memory=True)\n",
    "c2_r0_8_dl = DataLoader(dataset=c2_r0_8_subset, batch_size=32, shuffle=False, num_workers=0, pin_memory=True)\n",
    "c2_r1_dl = DataLoader(dataset=c2_r1_subset, batch_size=32, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "len(c2_r0_dl), len(c2_r0_2_dl), len(c2_r0_4_dl), len(c2_r0_6_dl), len(c2_r0_8_dl), len(c2_r1_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2_dls = [c2_r0_dl, c2_r0_2_dl, c2_r0_4_dl, c2_r0_6_dl, c2_r0_8_dl, c2_r1_dl]\n",
    "c1_dls = [c1_r0_dl, c1_r0_2_dl, c1_r0_4_dl, c1_r0_6_dl, c1_r0_8_dl, c1_r1_dl]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClientModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3)\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.pool(self.relu(self.conv4(x)))\n",
    "        return x\n",
    "\n",
    "class ClientClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features=4*4*256, out_features=10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(torch.flatten(x, 1))\n",
    "        return x\n",
    "\n",
    "class ServerModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv5 = nn.Conv2d(256, 512, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(2*2*512, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv5(x))\n",
    "        x = self.fc1(torch.flatten(x, 1))\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Test for each model combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_path = 'fmnist-exp/Baseline_exps/'\n",
    "experiment_paths = ['Base1/', 'Base2/', 'Base3/', 'Base4/', 'Base5/']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_weights(path):\n",
    "    client1_model = ClientModel()\n",
    "    client1_classifier = ClientClassifier()\n",
    "    client2_model = ClientModel()\n",
    "    client2_classifier = ClientClassifier()\n",
    "    server_model = ServerModel()\n",
    "\n",
    "    client1_model.load_state_dict(torch.load(path + 'Seventh10/client1_model_weights.pt'))\n",
    "    client2_model.load_state_dict(torch.load(path + 'Seventh10/client2_model_weights.pt'))\n",
    "    client1_classifier.load_state_dict(torch.load(path + 'Seventh10/client1_classifier_weights.pt'))\n",
    "    client2_classifier.load_state_dict(torch.load(path + 'Seventh10/client2_classifier_weights.pt'))\n",
    "    server_model.load_state_dict(torch.load(path + 'Seventh10/server_weights.pt'))\n",
    "\n",
    "    return client1_model, client1_classifier, client2_model, client2_classifier, server_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_client(model, classifier, test_dl):\n",
    "    model.eval()\n",
    "    classifier.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    with torch.inference_mode():\n",
    "        for i, data in enumerate(test_dl):\n",
    "            inputs, labels = data\n",
    "            model_outputs = model(inputs)\n",
    "            classifier_outputs = classifier(model_outputs)\n",
    "            _, predictions = torch.max(classifier_outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predictions == labels).sum().item()\n",
    "            del model_outputs, classifier_outputs, inputs\n",
    "    return round((correct / total)*100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_test_acc(client1_model, client1_classifier, client2_model, client2_classifier, server_model):\n",
    "    test_accs = {'client1' : [], 'client1_server' : [], 'client2' : [], 'client2_server' : [], }\n",
    "    for dl in c1_dls:\n",
    "        test_accs['client1'].append(test_client(client1_model, client1_classifier, dl))\n",
    "        test_accs['client1_server'].append(test_client(client1_model, server_model, dl))\n",
    "    for dl in c2_dls:\n",
    "        test_accs['client2'].append(test_client(client2_model, client2_classifier, dl))\n",
    "        test_accs['client2_server'].append(test_client(client2_model, server_model, dl))\n",
    "    return test_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _iterate_experiments(path):\n",
    "    client1_model, client1_classifier, client2_model, client2_classifier, server_model = _load_weights(path)\n",
    "    client1_model.eval()\n",
    "    client2_model.eval()\n",
    "    client1_classifier.eval()\n",
    "    client2_classifier.eval()\n",
    "    server_model.eval()\n",
    "    return _get_test_acc(client1_model, client1_classifier, client2_model, client2_classifier, server_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_dict = {}\n",
    "for idx, path in enumerate(experiment_paths):\n",
    "    exp_dict[idx] = _iterate_experiments(general_path + path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>client1</th>\n",
       "      <td>[89.9, 83.53, 79.07, 75.52, 72.63, 70.42]</td>\n",
       "      <td>[86.8, 84.43, 82.56, 81.14, 80.0, 79.28]</td>\n",
       "      <td>[76.84, 78.27, 79.27, 79.66, 80.28, 80.86]</td>\n",
       "      <td>[90.42, 75.77, 65.3, 57.39, 51.17, 46.32]</td>\n",
       "      <td>[89.12, 83.88, 80.21, 77.33, 74.93, 73.22]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client1_server</th>\n",
       "      <td>[90.3, 83.28, 78.3, 74.61, 71.44, 69.22]</td>\n",
       "      <td>[90.28, 87.25, 84.83, 83.23, 81.84, 80.69]</td>\n",
       "      <td>[84.44, 84.5, 84.53, 84.39, 84.31, 84.21]</td>\n",
       "      <td>[91.74, 76.5, 65.66, 57.46, 51.11, 46.08]</td>\n",
       "      <td>[89.74, 85.25, 82.06, 79.83, 77.9, 76.42]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client2</th>\n",
       "      <td>[95.68, 82.47, 73.1, 65.95, 60.32, 55.8]</td>\n",
       "      <td>[93.74, 84.23, 77.1, 72.1, 67.97, 64.78]</td>\n",
       "      <td>[84.88, 83.92, 82.71, 82.12, 81.42, 80.86]</td>\n",
       "      <td>[95.62, 80.32, 69.66, 61.42, 55.1, 49.97]</td>\n",
       "      <td>[94.32, 83.78, 76.19, 70.7, 66.37, 62.82]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client2_server</th>\n",
       "      <td>[96.58, 82.18, 72.14, 64.44, 58.33, 53.55]</td>\n",
       "      <td>[94.9, 85.38, 78.41, 73.47, 69.7, 66.35]</td>\n",
       "      <td>[83.98, 84.07, 83.9, 84.04, 84.18, 84.21]</td>\n",
       "      <td>[96.44, 80.37, 68.89, 60.27, 53.58, 48.22]</td>\n",
       "      <td>[95.22, 84.67, 77.0, 71.5, 67.26, 63.57]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         0  \\\n",
       "client1          [89.9, 83.53, 79.07, 75.52, 72.63, 70.42]   \n",
       "client1_server    [90.3, 83.28, 78.3, 74.61, 71.44, 69.22]   \n",
       "client2           [95.68, 82.47, 73.1, 65.95, 60.32, 55.8]   \n",
       "client2_server  [96.58, 82.18, 72.14, 64.44, 58.33, 53.55]   \n",
       "\n",
       "                                                         1  \\\n",
       "client1           [86.8, 84.43, 82.56, 81.14, 80.0, 79.28]   \n",
       "client1_server  [90.28, 87.25, 84.83, 83.23, 81.84, 80.69]   \n",
       "client2           [93.74, 84.23, 77.1, 72.1, 67.97, 64.78]   \n",
       "client2_server    [94.9, 85.38, 78.41, 73.47, 69.7, 66.35]   \n",
       "\n",
       "                                                         2  \\\n",
       "client1         [76.84, 78.27, 79.27, 79.66, 80.28, 80.86]   \n",
       "client1_server   [84.44, 84.5, 84.53, 84.39, 84.31, 84.21]   \n",
       "client2         [84.88, 83.92, 82.71, 82.12, 81.42, 80.86]   \n",
       "client2_server   [83.98, 84.07, 83.9, 84.04, 84.18, 84.21]   \n",
       "\n",
       "                                                         3  \\\n",
       "client1          [90.42, 75.77, 65.3, 57.39, 51.17, 46.32]   \n",
       "client1_server   [91.74, 76.5, 65.66, 57.46, 51.11, 46.08]   \n",
       "client2          [95.62, 80.32, 69.66, 61.42, 55.1, 49.97]   \n",
       "client2_server  [96.44, 80.37, 68.89, 60.27, 53.58, 48.22]   \n",
       "\n",
       "                                                         4  \n",
       "client1         [89.12, 83.88, 80.21, 77.33, 74.93, 73.22]  \n",
       "client1_server   [89.74, 85.25, 82.06, 79.83, 77.9, 76.42]  \n",
       "client2          [94.32, 83.78, 76.19, 70.7, 66.37, 62.82]  \n",
       "client2_server    [95.22, 84.67, 77.0, 71.5, 67.26, 63.57]  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(exp_dict)\n",
    "df.to_csv('fmnist-exp/Baseline_exps/test_accs.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_subset(client_model, classifier, server_model, threshold, OOD_labels, dataloader):\n",
    "    entropies = []\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    entr_counter = 0\n",
    "    correct_entr = 0\n",
    "    with torch.inference_mode():\n",
    "        for i, data in enumerate(dataloader):\n",
    "            inputs, labels = data\n",
    "            client_model_outputs = client_model(inputs)\n",
    "            outputs = classifier(client_model_outputs)\n",
    "            preds = outputs.clone().detach()\n",
    "            pred_distr = nn.functional.softmax(torch.tensor(outputs).clone().detach(), dim=-1)\n",
    "            entropies.append([(-torch.sum(tensor * torch.log2(tensor))) for i, tensor in enumerate(pred_distr)])\n",
    "            for idx, entr in enumerate(entropies[-1]):\n",
    "                if entr > threshold:\n",
    "                    entr_counter += 1\n",
    "                    correct_entr += 1 if labels[idx] in OOD_labels else 0\n",
    "                    preds[idx] =  server_model(client_model_outputs)[idx]\n",
    "            _, preds = torch.max(preds, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    return round(correct / total * 100, 2), entr_counter, correct_entr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _iterate_entropy_experiments(path):\n",
    "    client1_model, client1_classifier, client2_model, client2_classifier, server_model = _load_weights(path)\n",
    "    client1_model.eval(), client2_model.eval(), client1_classifier.eval()\n",
    "    client2_classifier.eval(), server_model.eval()\n",
    "    dict1, dict2 = {}, {}\n",
    "    thresholds = [0.05, 0.4, 0.8, 1.2, 2.3]\n",
    "    for thr in thresholds:\n",
    "        c1, c2 = [], []\n",
    "        for dl in c1_dls:\n",
    "            c1.append(test_subset(client1_model, client1_classifier, server_model, threshold=thr, OOD_labels=[5, 6, 7, 8, 9], dataloader=dl))\n",
    "        for dl in c2_dls:\n",
    "            c2.append(test_subset(client2_model, client2_classifier, server_model, threshold=thr, OOD_labels=[0, 1, 2, 3, 4], dataloader=dl))\n",
    "        dict1[thr], dict2[thr] = c1, c2\n",
    "    return dict1, dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexi\\AppData\\Local\\Temp\\ipykernel_4760\\764047283.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pred_distr = nn.functional.softmax(torch.tensor(outputs).clone().detach(), dim=-1)\n"
     ]
    }
   ],
   "source": [
    "exp_dict = {}\n",
    "for idx, path in enumerate(experiment_paths):\n",
    "    exp_dict[idx] = _iterate_entropy_experiments(general_path + path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_path = 'fmnist-exp/Baseline_exps/'\n",
    "experiment_paths = ['Base1/', 'Base2/', 'Base3/', 'Base4/', 'Base5/']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, path in enumerate(experiment_paths):\n",
    "    df1, df2 = pd.DataFrame(data=exp_dict[idx][0]), pd.DataFrame(data=exp_dict[idx][1])\n",
    "    df1['r'], df2['r'] = [0, 0.2, 0.4, 0.6, 0.8, 1], [0, 0.2, 0.4, 0.6, 0.8, 1]\n",
    "    df1.to_csv(general_path + path + 'c1_entropies_acc.csv'), df2.to_csv(general_path + path + 'c2_entropies_acc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0.05</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.8</th>\n",
       "      <th>1.2</th>\n",
       "      <th>2.3</th>\n",
       "      <th>r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>(89.76, 3578, 0)</td>\n",
       "      <td>(89.74, 1980, 0)</td>\n",
       "      <td>(89.92, 1249, 0)</td>\n",
       "      <td>(89.78, 582, 0)</td>\n",
       "      <td>(89.24, 11, 0)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>(85.27, 4497, 919)</td>\n",
       "      <td>(85.25, 2618, 638)</td>\n",
       "      <td>(85.35, 1707, 458)</td>\n",
       "      <td>(84.95, 888, 306)</td>\n",
       "      <td>(83.98, 13, 2)</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>(82.07, 5427, 1849)</td>\n",
       "      <td>(81.99, 3250, 1270)</td>\n",
       "      <td>(82.16, 2154, 905)</td>\n",
       "      <td>(81.67, 1165, 583)</td>\n",
       "      <td>(80.31, 15, 4)</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>(79.84, 6357, 2779)</td>\n",
       "      <td>(79.76, 3861, 1881)</td>\n",
       "      <td>(79.86, 2602, 1353)</td>\n",
       "      <td>(79.34, 1449, 867)</td>\n",
       "      <td>(77.45, 22, 11)</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>(77.92, 7290, 3712)</td>\n",
       "      <td>(77.88, 4503, 2523)</td>\n",
       "      <td>(77.93, 3089, 1840)</td>\n",
       "      <td>(77.32, 1760, 1178)</td>\n",
       "      <td>(75.06, 28, 17)</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>(76.44, 8219, 4641)</td>\n",
       "      <td>(76.41, 5130, 3150)</td>\n",
       "      <td>(76.51, 3546, 2297)</td>\n",
       "      <td>(75.86, 2054, 1472)</td>\n",
       "      <td>(73.36, 36, 25)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                 0.05                  0.4                  0.8  \\\n",
       "0           0     (89.76, 3578, 0)     (89.74, 1980, 0)     (89.92, 1249, 0)   \n",
       "1           1   (85.27, 4497, 919)   (85.25, 2618, 638)   (85.35, 1707, 458)   \n",
       "2           2  (82.07, 5427, 1849)  (81.99, 3250, 1270)   (82.16, 2154, 905)   \n",
       "3           3  (79.84, 6357, 2779)  (79.76, 3861, 1881)  (79.86, 2602, 1353)   \n",
       "4           4  (77.92, 7290, 3712)  (77.88, 4503, 2523)  (77.93, 3089, 1840)   \n",
       "5           5  (76.44, 8219, 4641)  (76.41, 5130, 3150)  (76.51, 3546, 2297)   \n",
       "\n",
       "                   1.2              2.3    r  \n",
       "0      (89.78, 582, 0)   (89.24, 11, 0)  0.0  \n",
       "1    (84.95, 888, 306)   (83.98, 13, 2)  0.2  \n",
       "2   (81.67, 1165, 583)   (80.31, 15, 4)  0.4  \n",
       "3   (79.34, 1449, 867)  (77.45, 22, 11)  0.6  \n",
       "4  (77.32, 1760, 1178)  (75.06, 28, 17)  0.8  \n",
       "5  (75.86, 2054, 1472)  (73.36, 36, 25)  1.0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('fmnist-exp\\Baseline_exps\\Base5\\c1_entropies_acc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0.05</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.8</th>\n",
       "      <th>1.2</th>\n",
       "      <th>2.3</th>\n",
       "      <th>r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>(95.22, 3330, 0)</td>\n",
       "      <td>(95.2, 1231, 0)</td>\n",
       "      <td>(95.18, 624, 0)</td>\n",
       "      <td>(94.82, 220, 0)</td>\n",
       "      <td>(94.34, 5, 0)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>(84.67, 4231, 901)</td>\n",
       "      <td>(84.67, 1752, 521)</td>\n",
       "      <td>(84.5, 951, 327)</td>\n",
       "      <td>(84.23, 389, 169)</td>\n",
       "      <td>(83.75, 19, 14)</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>(77.0, 5109, 1779)</td>\n",
       "      <td>(76.99, 2261, 1030)</td>\n",
       "      <td>(76.8, 1256, 632)</td>\n",
       "      <td>(76.59, 539, 319)</td>\n",
       "      <td>(76.16, 35, 30)</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>(71.51, 5992, 2662)</td>\n",
       "      <td>(71.46, 2794, 1563)</td>\n",
       "      <td>(71.35, 1589, 965)</td>\n",
       "      <td>(71.04, 696, 476)</td>\n",
       "      <td>(70.65, 46, 41)</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>(67.27, 6872, 3542)</td>\n",
       "      <td>(67.21, 3309, 2078)</td>\n",
       "      <td>(67.06, 1886, 1262)</td>\n",
       "      <td>(66.67, 829, 609)</td>\n",
       "      <td>(66.3, 48, 43)</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>(63.58, 7762, 4432)</td>\n",
       "      <td>(63.53, 3825, 2594)</td>\n",
       "      <td>(63.45, 2193, 1569)</td>\n",
       "      <td>(63.1, 988, 768)</td>\n",
       "      <td>(62.77, 52, 47)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                 0.05                  0.4                  0.8  \\\n",
       "0           0     (95.22, 3330, 0)      (95.2, 1231, 0)      (95.18, 624, 0)   \n",
       "1           1   (84.67, 4231, 901)   (84.67, 1752, 521)     (84.5, 951, 327)   \n",
       "2           2   (77.0, 5109, 1779)  (76.99, 2261, 1030)    (76.8, 1256, 632)   \n",
       "3           3  (71.51, 5992, 2662)  (71.46, 2794, 1563)   (71.35, 1589, 965)   \n",
       "4           4  (67.27, 6872, 3542)  (67.21, 3309, 2078)  (67.06, 1886, 1262)   \n",
       "5           5  (63.58, 7762, 4432)  (63.53, 3825, 2594)  (63.45, 2193, 1569)   \n",
       "\n",
       "                 1.2              2.3    r  \n",
       "0    (94.82, 220, 0)    (94.34, 5, 0)  0.0  \n",
       "1  (84.23, 389, 169)  (83.75, 19, 14)  0.2  \n",
       "2  (76.59, 539, 319)  (76.16, 35, 30)  0.4  \n",
       "3  (71.04, 696, 476)  (70.65, 46, 41)  0.6  \n",
       "4  (66.67, 829, 609)   (66.3, 48, 43)  0.8  \n",
       "5   (63.1, 988, 768)  (62.77, 52, 47)  1.0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('fmnist-exp\\Baseline_exps\\Base5\\c2_entropies_acc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
